{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e960020",
   "metadata": {},
   "source": [
    "# **Getting Started with Generative AI APIs: OpenAI and Gemini in Practice**\n",
    "\n",
    "This notebook follows the step-by-step guide from Module 4 of the **PrograMaria Sprint Generative AI**, lesson [\"Primeiros Passos com APIs de IA Generativa: OpenAI e Gemini na Pr谩tica\"](https://www.youtube.com/watch?v=4pKlrdOU8nM&t=233s). It demonstrates how to use the OpenAI and Gemini APIs to generate text content.\n",
    "\n",
    ">While following the core concepts, Ive made modifications to certain parts of the code, such as adjusting functions, adding clarifications, and testing alternative approaches, to better suit learning and reproducibility.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd99bd",
   "metadata": {},
   "source": [
    "## **1. Setting Up the Environment**\n",
    "\n",
    "### **1.1 Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run only once per environment)\n",
    "%pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46748d93",
   "metadata": {},
   "source": [
    "### **1.2 Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9723e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e574d",
   "metadata": {},
   "source": [
    "## **2. Using the OpenAI API**\n",
    "\n",
    "### **2.1 Load Environment Variables**\n",
    "\n",
    "Load the API key and model name from the `.env` file. Ensure your `.env` file contains:\n",
    "\n",
    "- `OPENAI_API_KEY`: Your OpenAI API key.\n",
    "- `OPENAI_MODEL`: The model you want to use (e.g., `gpt-3.5-turbo`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key and model from environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = os.getenv(\"OPENAI_MODEL\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9ada5",
   "metadata": {},
   "source": [
    "### **2.2 Initialize the OpenAI Client**\n",
    "\n",
    "Create a client instance to interact with the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae5eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI Client\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b66be3",
   "metadata": {},
   "source": [
    "### **2.3 Define a Helper Function to Generate Text**\n",
    "\n",
    "This function sends a prompt to the OpenAI API and returns the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29ef3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt: str) -> str:\n",
    "    \"\"\"Generates text using the specified OpenAI model.\n",
    "    Args:\n",
    "        prompt (str): User input text.\n",
    "    Returns:\n",
    "        str: Model-generated text.\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=prompt\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead398e1",
   "metadata": {},
   "source": [
    "### **2.4 Test the Function**\n",
    "\n",
    "Generate a motivational message for someone learning Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb881a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "prompt = \"Write a motivational message for someone learning Python.\"\n",
    "result = generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8f8a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write a motivational message for someone learning Python.\n",
      "Generated text: Absolutely! Heres a motivational message for you:\n",
      "\n",
      "---\n",
      "\n",
      " **Keep Going!** \n",
      "\n",
      "Hey there, future Pythonista!  Learning Python can be challenging, but remember that every expert was once a beginner. Each line of code you write brings you closer to mastering the language. Embrace the mistakesthey are simply stepping stones to your success. \n",
      "\n",
      "Celebrate your progress, no matter how small, and dont hesitate to ask for help when you need it. The coding community is incredibly supportive! \n",
      "\n",
      "Stay curious, keep experimenting, and dont forget to have fun along the way. Youve got this! Keep pushing forward, and soon you'll be solving problems and creating amazing projects with confidence. \n",
      "\n",
      "Happy coding! \n",
      "\n",
      "--- \n",
      "\n",
      "Keep believing in yourself! You've got the potential to achieve great things!\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt:\", prompt)\n",
    "print(\"Generated text:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fcd13",
   "metadata": {},
   "source": [
    "### **2.5 Try Your Own Prompts**\n",
    "\n",
    "Experiment with different prompts to see the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff08c705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here are three creative names for a coffee shop:\\n\\n1. **Brewed Awakening**\\n2. **Caf茅 Canvas**\\n3. **Mugshot Mocha**'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Give me 3 creative names for a coffee shop.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7713750",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **3. Using the Gemini API**\n",
    "\n",
    "### **3.1 Install the Gemini Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44d62cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bcbb3",
   "metadata": {},
   "source": [
    "### **3.2 Import Libraries**\n",
    "\n",
    "Import the required library for Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58040218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb7b62",
   "metadata": {},
   "source": [
    "### **3.3 Load Environment Variables**\n",
    "\n",
    "Load the API key and model name from the `.env` file. Ensure your `.env` file contains:\n",
    "\n",
    "- `GEMINI_API_KEY`: Your Gemini API key.\n",
    "- `GEMINI_MODEL`: The model you want to use (e.g., `gemini-pro`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be8feadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key and model from environment variables\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_model = os.getenv(\"GEMINI_MODEL\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e6302",
   "metadata": {},
   "source": [
    "### **3.4 Initialize the Gemini Client**\n",
    "\n",
    "Configure the Gemini client with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa3ba7",
   "metadata": {},
   "source": [
    "### **3.5 Check Available Generative Models**\n",
    "\n",
    "List all available generative models supported by Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9d165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all available models in the Gemini API\n",
    "for m in genai.list_models():\n",
    "    # Check if the model supports content generation\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        # Print the name of models that can generate content\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26cdbd",
   "metadata": {},
   "source": [
    "### **3.6 Generate Content with Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44c2671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na Westeros de gelo e fogo, o chifre do unic贸rnio, antes um farol de pureza e cura, tornou-se apenas mais um trof茅u ensanguentado cobi莽ado por lordes no jogo dos tronos.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GenerativeModel with the specified Gemini model (e.g. \"gemini-1.5-flash\")\n",
    "model = genai.GenerativeModel(gemini_model)\n",
    "\n",
    "# Generate content using a Portuguese prompt about a unicorn in Game of Thrones\n",
    "response = model.generate_content(\n",
    "    \"Escreva uma hist贸ria em uma frase sobre um unic贸rnio no mundo de game of thrones\"\n",
    ")\n",
    "\n",
    "# Print the generated text response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404d811",
   "metadata": {},
   "source": [
    "### **3.7 Customize Generation Settings**\n",
    "\n",
    "Adjust the `temperature` and `max_output_tokens` for more creative or controlled outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce8127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate content with customized parameters\n",
    "response = model.generate_content(\n",
    "    # Portuguese prompt requesting a one-sentence GoT unicorn story\n",
    "    \"Escreva uma hist贸ria em uma frase sobre um unic贸rnio no mundo de Game of Thrones\",\n",
    "    \n",
    "    # Generation configuration settings:\n",
    "    generation_config={\n",
    "        \"temperature\": 1.5,  # Higher creativity/randomness (0.0-2.0)\n",
    "        \"max_output_tokens\": 100  # Limit response length to ~100 tokens\n",
    "    },\n",
    "    \n",
    "    # Safety filters to moderate content:\n",
    "    safety_settings=[{\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",  # Type of harmful content\n",
    "        \"threshold\": 3  # BLOCK_MOST threshold (1-4 scale)\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Output the generated text response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fce906",
   "metadata": {},
   "source": [
    "## **4. Conclusion**\n",
    "\n",
    "This notebook provides a practical introduction to using the OpenAI and Gemini APIs for text generation. Experiment with different prompts and settings to explore the capabilities of these models.\n",
    "\n",
    "For more details, check out the [official repository](https://github.com/lauraDamacenoAlmeida/primeiros_passos_AI_Gen). Happy coding! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".iaGen_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
